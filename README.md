# Year 4 MEng Electrical Engineering Human-Centered Robotics 2022 Send-a-bot

Welcome to the Send-a-bot repository! For our Year 4 MEng Electrical and Electronics Engineering HCR coursework at Imperial College London, we have developed a robot system that delivers to people via computer vision, speech interaction and navigation.

## Requirements

- Linux machine (20.04)
- [ROS noetic](http://wiki.ros.org/noetic)
- [Pioneer3-AT](https://www.generationrobots.com/media/Pioneer3AT-P3AT-RevA-datasheet.pdf)
- [Intel® RealSense™ LiDAR Camera L515](https://www.intelrealsense.com/lidar-camera-l515/)
- [OAK—D Camera](https://store.opencv.ai/products/oak-d)
- [Snowball Ice Blue Microphones](https://www.bluemic.com/en-gb/products/snowball/)

## Assembly

The send-a-bot is assembled as following and is controlled via a laptop
![Alt Text](https://github.com/yw14218/Send-a-bot/blob/master/doc/thumbnail_Image.jpg)

## Install
Copy the project on the catkin workspace

```
$ cd catkin_ws
$ cd src
$ git clone
```

Install depenancies

``` 
$ rosdep update
$ cd ..
$ rosdep update rosdep install --rosdistro noetic --ignore-src --from-paths src
$ catkin_make
```

## Repository structure
This repository involves many submodules since local changes are made in the original source code. The main dev place is within [ros-pioneer3at](https://github.com/yw14218/Send-a-bot/tree/master/ros-pioneer3at/launch) and [rosaria_client](https://github.com/yw14218/Send-a-bot/tree/master/rosaria_client/src)

For your interest, I will briefly outline the purpose of each package:
- [depthai-python](https://github.com/yw14218/Send-a-bot/tree/master/depthai-python) dependencies for OAK-D camera
- [depthimage_to_laserscan](https://github.com/yw14218/Send-a-bot/tree/master/depthimage_to_laserscan) and [pointcloud_to_laserscan](https://github.com/yw14218/Send-a-bot/tree/master/pointcloud_to_laserscan) ros packages used to convert l515 camera PointClouds into LaserScans, depthimage_to_laser scan is more efficient, but less accurate
- [ira_laser_tools](http://wiki.ros.org/ira_laser_tools) ros package used to merge LaserScans generated by the left and right l515 cameras
- [modelplace-api](https://github.com/yw14218/Send-a-bot/tree/master/modelplace-api) and [oak-model-samples](https://github.com/yw14218/Send-a-bot/tree/master/oak-model-samples) APIs and trained neuron network blobs for the OAK-D camera
- [robot_localization](http://docs.ros.org/en/melodic/api/robot_localization/html/index.html) and [https://github.com/yw14218/Send-a-bot/tree/master/robot_pose_ekf](https://github.com/yw14218/Send-a-bot/tree/master/robot_pose_ekf) packages used to perform kalman filtering on the odometry published from the wheel encoder and the vision odometry published from the RGBD vo node
- [rosaria](https://github.com/yw14218/Send-a-bot/tree/master/rosaria) driver for P3-AT, you should comment out the tf odom->baselink if you don't want to use wheel odometry, which is not very accurate
- [rosaria_client](https://github.com/yw14218/Send-a-bot/tree/master/rosaria_client) client and server, main entrance scripts to interact with send-a-bot for functions such as social navigation and object delivery
- [rtabmap_ros](https://github.com/yw14218/Send-a-bot/tree/master/rtabmap_ros) ros package used to generate vision odometry from the two l515 cameras and perform vision-Lidar SLAM, this SLAM technique is not ideal for hallway environments due to repetitive patterns and lack of visual features 
- [slam_gmapping](https://github.com/yw14218/Send-a-bot/tree/master/slam_gmapping) ros package used to perform 2D Lidar SLAM

## Repository usage
